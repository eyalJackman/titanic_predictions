{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting survival on the Titanic\n",
    "- Uses the Kaggle dataset found [here](https://www.kaggle.com/competitions/titanic/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "drop_cols = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\" ]\n",
    "\n",
    "# regex.split(r\"\\d\", train_data[\"Ticket\"])\n",
    "# train_data[\"Ticket\"] = train_data[\"Ticket\"].apply(lambda row: re.split(r\"\\D\", row)[-1])\n",
    "# train_data[\"Ticket\"] = pd.to_numeric(train_data[\"Ticket\"], errors='coerce').fillna(0).astype(int)\n",
    "# ticket_data = train_data[\"Ticket\"]\n",
    "# Normalize the data\n",
    "\n",
    "\n",
    "# normalized_data = (train_data[\"Ticket\"] - train_data[\"Ticket\"].min()) / (train_data[\"Ticket\"].max() - train_data[\"Ticket\"].min())\n",
    "# normalized_data = train_data[\"Ticket\"].add()\n",
    "\n",
    "train_data.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "# Fill in missing values\n",
    "train_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(train_data[\"Embarked\"].mode(), inplace=False)\n",
    "gender_data = train_data.groupby(\"Sex\")[\"Age\"].mean()\n",
    "train_data[\"Age\"] = train_data.apply((lambda row: row[\"Age\"] if not pd.isnull(row[\"Age\"]) else gender_data[row[\"Sex\"]]), axis=1)\n",
    "\n",
    "# Normalize Data: Age, Fare\n",
    "age_col = train_data[\"Age\"]\n",
    "train_data[\"Age\"] = (age_col - age_col.min()) / (age_col.max() - age_col.min())\n",
    "fare_col = train_data[\"Fare\"]\n",
    "train_data[\"Fare\"] = (fare_col - fare_col.min()) / (fare_col.max() - fare_col.min())\n",
    "\n",
    "# Standardize Data: Parch, SibSp\n",
    "parch_col = train_data[\"Parch\"]\n",
    "train_data[\"Parch\"] = (parch_col - parch_col.mean()) / parch_col.std()\n",
    "sibsp_col = train_data[\"SibSp\"]\n",
    "train_data[\"SibSp\"] = (sibsp_col - sibsp_col.mean()) / sibsp_col.std()\n",
    "\n",
    "# Remove Survived Data\n",
    "Y = train_data[\"Survived\"]\n",
    "train_data.drop([\"Survived\"], axis=1, inplace=True)\n",
    "\n",
    "# Make Indicator Values for Categorical Data\n",
    "train_data[\"Sex\"].replace({\"male\": False, \"female\": True}, inplace=True)\n",
    "dummy_cols = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "X = pd.get_dummies(train_data, columns=dummy_cols)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "# sr = pd.Series([1, 2, 10, 5, 2,34, 5])\n",
    "# train_data.plot(subplots=True)\n",
    "# train_data.hist(bins=20)\n",
    "# train_data[\"SibSp\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Testing\n",
    "Applying 5-Fold Grid Search Cross-Validation to each of the three types of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7988826815642458"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "## Kernel, Regularization Parameter, and Degree (for Polynomial Kernel)\n",
    "# [best value], # [attempted values]\n",
    "hyperparams_svm = {\n",
    "    \"kernel\": [\"poly\"], # [\"linear\", \"rbf\", \"sigmoid\", \"poly\"],\n",
    "    \"C\": [100], # [0.01, 0.1, 1, 10, 100],\n",
    "    \"degree\": [4] # [2, 3, 4, 5, 6]\n",
    "}\n",
    "\n",
    "svm_clf = svm.SVC(random_state=0)\n",
    "gscv_svm = GridSearchCV(svm_clf, hyperparams_svm, verbose=0)\n",
    "gscv_svm.fit(X_train, Y_train)\n",
    "\n",
    "accuracy_score(Y_test, gscv_svm.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8212290502793296"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "## Activation Function, Solver, Sizes of Hideen Layers, Regularization Parameter\n",
    "# [best value], # [attempted values]\n",
    "hyperparams_mlp = {\n",
    "          \"activation\" : [\"relu\"], # [\"logistic\", \"relu\", \"tanh\"],\n",
    "           # \"solver\" : [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "           \"hidden_layer_sizes\" : [(6, 6, 6)], # [(8,8,8), (6, 6, 6), (6, 6), (4, 4, 4), (4, 4), (12, 12, 12), (12, 12), (12,), (6,), (2,), (5,), (10,), (32,), (32, 32), (50, 50)],\n",
    "           \"alpha\" : [1e-5] # [1e-5, 1e-4, 1e-3, 1e-2, 1e-1] \n",
    "         }\n",
    "\n",
    "mlp_clf = MLPClassifier(random_state=0, max_iter=1000)\n",
    "gscv_mlp = GridSearchCV(mlp_clf, hyperparams_mlp, verbose=1)\n",
    "gscv_mlp.fit(X_train, Y_train)\n",
    "\n",
    "accuracy_score(Y_test, gscv_mlp.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8268156424581006"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Number of Trees, Max Depth\n",
    "# [best value], # [attempted values]\n",
    "hyperparams = {\n",
    "    \"n_estimators\": [1000], # [100, 500, 1000, 2000, 5000, 10000],\n",
    "    \"max_depth\": [5] # [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "gscv_rfc = GridSearchCV(rfc, hyperparams, verbose=1, scoring=\"recall\")\n",
    "gscv_rfc.fit(X_train, Y_train)\n",
    "\n",
    "accuracy_score(Y_test, gscv_rfc.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
